{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGeneration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3qUQRMhURvMSsqFG8aaOR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtao22/PythonAI/blob/main/NLP/TextGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEnYBySEEltE"
      },
      "source": [
        "#import\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import numpy as np"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pnOLQISE4r0"
      },
      "source": [
        "#upload\n",
        "path = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om28lGxqFWyc"
      },
      "source": [
        "#read\n",
        "text = open(path,'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR-uOeOUHtz4"
      },
      "source": [
        "#encode\n",
        "vocab = sorted(set(text))\n",
        "#find unique characters\n",
        "c2i = {u:i for i, u in enumerate(vocab)}\n",
        "i2c = np.array(vocab)\n",
        "\n",
        "def text2int(text):\n",
        "  return np.array([c2i[c] for c in text])\n",
        "def int2text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(i2c[ints])\n",
        "inttext = text2int(text)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7dQBSvDZuje"
      },
      "source": [
        "#input 42 char sequence and output is that sequence translated right by 1 char\n",
        "chardata = tf.data.Dataset.from_tensor_slices(inttext)\n",
        "sequences = chardata.batch(43, drop_remainder=True)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM6I_hweUWk1"
      },
      "source": [
        "#create splitting function\n",
        "def splitX(x):\n",
        "  testX = x[:-1]\n",
        "  testY = x[1:]\n",
        "  return testX,testY\n",
        "\n",
        "#split\n",
        "dataset = sequences.map(splitX)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N97RjiUYvoz"
      },
      "source": [
        "data = dataset.shuffle(10000).batch(64, drop_remainder=True)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPkkFJ-TZ_aH",
        "outputId": "84f11978-bd33-47bf-b6ff-f7ee52449a08"
      },
      "source": [
        "#create arch building function\n",
        "def make_arch(vocab_size, embedding_dim, units, batch_size):\n",
        "  arch = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size,None]),\n",
        "    tf.keras.layers.LSTM(units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return arch\n",
        "\n",
        "arch = make_arch(len(vocab), 256, 1024, 64)\n",
        "arch.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5oh4PHrc7_h"
      },
      "source": [
        "#create loss function\n",
        "def loss(Y,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(Y, logits, from_logits=True)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZci91endWva"
      },
      "source": [
        "#compile arch\n",
        "arch.compile(optimizer='adam',loss=loss)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LM10s-cddMp"
      },
      "source": [
        "#set up checkpoints \n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join('./training_checkpoints', \"ckpt_{epoch}\"), save_weights_only=True)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ6iHsg4eVu6"
      },
      "source": [
        "#train\n",
        "hist = arch.fit(data, epochs=100, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNwJ84pvhooI"
      },
      "source": [
        "#rebuild model from checkpoint\n",
        "arch = make_arch(len(vocab), 256, 1024, 1)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWjnzbJTiGhr"
      },
      "source": [
        "#load in previously trained weights\n",
        "arch.load_weights(tf.train.latest_checkpoint('./training_checkpoints'))\n",
        "arch.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T12qKWDVitYS"
      },
      "source": [
        "#create text generating function\n",
        "def generate(model, input, num): #num = number of characters to generate\n",
        "  #vectorizing\n",
        "  input_data = [c2i[s] for s in input]\n",
        "  input_data = tf.expand_dims(input_data,0)\n",
        "\n",
        "  result = []\n",
        "  temp = 1.0 #temperature varies directly with how \"surprising\" the text is \n",
        "  model.reset_states()\n",
        "  for i in range(num):\n",
        "    predictions = model(input_data)\n",
        "    predictions = tf.squeeze(predictions,0) #remove batch dim\n",
        "\n",
        "    #use categorical distribution to predict character returned by model\n",
        "    predictions = predictions/temp\n",
        "    predicted_val = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    #make predicted character the next input\n",
        "    input_data = tf.expand_dims([predicted_val],0)\n",
        "    result.append(i2c[predicted_val])\n",
        "  return input + ''.join(result)\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kycsM6akkR1",
        "outputId": "d8337cc4-d09e-46ec-958b-c02a6c379363"
      },
      "source": [
        "inp = input(\"Type Starting string: \")\n",
        "num = int(input(\"Type the number of characters to generate: \"))\n",
        "print(generate(arch,inp,num))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type Starting string: romeo\n",
            "Type the number of characters to generate: 800\n",
            "romeo; or:\n",
            "'Tis the moon eyes and weeps,\n",
            "But NENIUS:\n",
            "You have done! Come, son, how ikes, to what I saw, to make you fall? Tybalt s love?\n",
            "\n",
            "SICINIUS:\n",
            "What's him that I so? Well save thy not so train\n",
            "I am too near as of your worship's points\n",
            "As fond that place, it is enemies,\n",
            "Our fiends.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Mistake not what; that to smile with God about,\n",
            "And say 'Widown you know me?\n",
            "\n",
            "MERCUTIO:\n",
            "Gony, come, you must know securely set his remedy pass.\n",
            "\n",
            "ABHORSON:\n",
            "Go in, Bereftu wilt have him come with thee:\n",
            "Now incul, lest you be more.\n",
            "\n",
            "BRUTUS:\n",
            "There's never and women: 'bout we will call thee Clasting of his blood. The willon the world I loved and to him pleaseth.\n",
            "\n",
            "Third Gentleman:\n",
            "Who courches wer honour-flaw, I'll answer him\n",
            "for their boar-siles account of your Lord George doubt.\n",
            "\n",
            "YORK:\n",
            "What, wilt t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}